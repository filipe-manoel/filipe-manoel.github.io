---
title: |
  ![](UF.jpg){width=10%}

  Cross-validation scheme 1
author: 

    - Marco Antonio Peixoto, Post doc^[University of Florida, deamorimpeixotom@ufl.edu]
  
output: 
  html_document:
    toc: FALSE
    toc_float: FALSE
    theme: flatly
    highlight: haddock
bibliography: references.bib
csl: apa.csl   
---

```{=html}
<style type="text/css">
  body{
  font-size: 12pt;
}
</style>
```


## 1. Genomic selection using multiple-trait information

In this practice, we will show how to implement a **GBLUP** model in a CV1 scheme using BGLR [@perez2022multitrait] in a Multienvironment framework.

To perform the analyses, we will need the following packages:

```{r echo=FALSE, warning=FALSE,eval=TRUE}
rm(list=ls())
require(AGHmatrix)
require(BGLR)
require(tidyverse)
require(dplyr)
require(ggplot2)
```

<br>

### Dataset 

This dataset was simulated using the coalescent theory implemented in $AlphasimR$ package [@gaynor2021alphasimr]. This dataset mimic an evaluation of 500 maize genotypes, in six location, and four traits were measured. Also, a set of 3000 single nucleotide polymorphism (SNPs) were randomly sampled through the 10 pair of chromosomes.

**Phenotypic data**  
We generated BLUEs (best linear unbiased estimation) for each trait, and it can be loaded from *Phenotypes.csv*.

```{r echo=TRUE}
# Loading the data
Phenotypes = read.csv("Phenotypes.csv")

# As factor
Phenotypes$Genotype = Phenotypes$Genotype %>% as.factor
Phenotypes$Env = Phenotypes$Env %>% as.factor

```



```{r}
Phenotypes[,c(1,3:6)] %>%
  pivot_longer(., cols = c('Trait1','Trait2','Trait3','Trait4')) %>% 
ggplot(., aes(x = Env, y = value)) +
  geom_boxplot(color="brown", fill="orange", alpha=0.2) + 
  theme(strip.text = element_text(face = "bold", size = 20, colour = 'blue'))+
  labs(x = 'Environment', title = "Traits (BLUEs) distribution across environments",y="Density")+
  facet_wrap(~name,scales = "free")


```
<br>


**Genomic data**  
The genomic data (3000 SNP markers) was coded as 0,1,2 for aa,Aa,AA, respectively. The dataset for all 500 genotypes can be loaded from **Genotypes.csv**.

```{r echo=FALSE}
# SNPs
Genotypes = as.matrix(read.csv("Genotypes.csv"))

#Names
rownames(Genotypes)= unique(Phenotypes$Genotype)

```

**Creating G Matrix**

Here, we will compose the additive relationship matrix (*G* matrix) following the propositions made by @vanraden2008efficient in the AGHmatrix package [@amadeu2016aghmatrix].

```{r echo=FALSE, eval=TRUE}
# Additive matrix
GMat = AGHmatrix::Gmatrix(Genotypes) 

```

<br>

### Multitrait Model


**Statistical model**

The **GBLUP** model in a multitrait framework is given as follows:

$$
y = 1u + Za + e
$$

where $y$ is the matrix of BLUEs data for the target traits; $u$ represents the mean (fixed); $a$ is the matrix of genotype effects (assumed to be random), where $a \sim N(0,\sum_a\otimes G)$, $G$ is a matrix that describes the genomic similarities between pair of genotypes and $\sum_a$ represents the genetic covariance matrix; and $e$ is the  residuals (random), where $e\sim N(0,\sum_{res}\otimes I)$, $\sum_{res}$ is the residual covariance matrix. The letter $Z$ refers to the incidence matrix for $a$. 
<br>

## GBLUP STM BGLR()

Using the trait 1 from one environment.

```{r echo=TRUE, eval=TRUE}
# Organizing the phenotypic data
Y<- Phenotypes[Phenotypes$Env == 1,c(1:3)] 

# Scale the pheno data
y = scale(Y[,3])

```

Deploy the model using BGLR() function

```{r, echo=-TRUE, eval=TRUE}

###----------- Parameters for the folds
nReps = 5 #change here for more repetitions (10-20 is a good fit)
nFolds = 5 # 5 is reasonable, but it depends of or dataset size

###----------- Output for the estimated values
yHatCV=rep(NA,length(Y$Trait1))
pred = data.frame()

###----------- Model
# Phenodata
y = as.matrix(y)

# Time for the loop
set.seed(0928761) 
 for(Rep in 1:nReps){
   
 folds=sample(1:nFolds,size=length(Y$Trait1),replace=T)  
 
  for(i in 1:max(folds)){
  	tst=which(folds==i)
  	yNA=y
    yNA[tst]=NA
    # model
    fm=BGLR(y=yNA,
            ETA=list(list(K=GMat,model='RKHS')),
            nIter=1200,
            burnIn=120,
            verbose = FALSE)
    # Predicted values
    yHatCV[tst]=fm$yHat[tst]
  }
 # Accuracy for each fold
 pred=rbind(pred, 
            data.frame(Repetitions = Rep,
                       Cor=cor(yHatCV, y)))
}
 

## Mean for the correlation
mean(pred$Cor)

```

<br>

## GBLUP MTM Multitrait()

Using the trait 1 over four environments.

```{r echo=TRUE, eval=TRUE}
# Organizing the phenotypic data

Y<- Phenotypes[,c(1,2,3)] %>%  
  pivot_wider(., names_from = 'Env', values_from = 'Trait1') 

# Scale the data
y = scale(Y[,-1])

```
Deploy the model using Multitrait() function

```{r, echo = TRUE, eval=TRUE}
# CROSS-VALIDATION CV1 (Predicting traits for new lines)

# nFolds
nFolds = 5
nReps = 5

# Set file for accuracy storage
M_GB = data.frame()
yHat = data.frame(matrix(nrow = 500, ncol = 4))

set.seed(0928761)
for (i in 1:nFolds){
##>>----- Partitions for a 5-FCV
folds=sample(1:nFolds,size=dim(y)[1],replace=T)  
  
##>>----- Model using multitrait

for(p in 1:nReps){
  
  tst=which(folds==p)
  yNA=y
  yNA[tst]=NA
  
  fm <- Multitrait(y=yNA,
                   ETA = list(list(K=GMat,model='RKHS')),
                   resCov = list(type="DIAG"),
                   nIter = 1200,
                   burnIn = 120,
                   saveAt='MGB_',
                   verbose = FALSE)
  
  yHat[tst,] = fm$ETAHat[tst,]
}
PC = diag(cor(yHat,y))
M_GB = rbind(M_GB, data.frame(Acc=PC))

}

```




<br>

## GBLUP MTM BGLR()

Using the 4 traits for environment 1.

```{r echo=TRUE, eval=TRUE}
# Organizing the phenotypic data
Y<- Phenotypes[Phenotypes$Env == 4,] 

# Scale the pheno data
y = scale(Y[,-c(1:2)])

```



<br>

```{r, echo=TRUE}

#--- 1. Setting the NA's
set.seed(12345)
yNA2 <- y
yNA2[sample(1:dim(Y)[1],100),] <- NA

#--- 2. Model
fm2 <- Multitrait(
         y = yNA2,
         ETA = list(A=list(K=GMat, model='RKHS', Cov = list(type = 'UN'))),
         resCov = list(type = 'DIAG'), 
         nIter = 1200, 
         burnIn = 120, 
         thin = 5,
         verbose = FALSE)

#--- 3.  Extracting the estimated parameters
YHatInt2 <- fm2$ETAHat

#--- 4. Predictive correlation
  test2<-is.na(yNA2)
  tstB<-test2[,1] # Same position for all traits
  CORB.T1<-cor(YHatInt2[tstB,1],y[tstB,1])
  CORB.T2<-cor(YHatInt2[tstB,2],y[tstB,2])
  CORB.T3<-cor(YHatInt2[tstB,3],y[tstB,3])
  CORB.T4<-cor(YHatInt2[tstB,4],y[tstB,4])
  
#--- 4. Extracting estimates of variance parameters
(CORB.RES<-fm2$resCov$R) # residual covariance matrix
(CORB.u<-fm2$ETA[[1]]$Cov$Omega) # genetic covariance matrix UE

#--- 5. Trait correlation  
cov2cor(CORB.u)
```




## References

::: {#refs}
:::


